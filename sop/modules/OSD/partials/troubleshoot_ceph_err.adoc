==== Troubleshooting Ceph ====
**Ceph commands**
Some common commands to troubleshoot a Ceph cluster:
- ceph status
- ceph osd status
- cepd osd df
- ceph osd utilization
- ceph osd pool stats
- ceph osd tree
- ceph pg stat

The first two status commands provide the overall cluster health. The normal state for cluster operations is HEALTH_OK, but will still function when the state is in a HEALTH_WARN state. If you are in a WARN state, then the cluster is in a condition that it may enter the HEALTH_ERROR state at which point all disk I/O operations are halted. If a HEALTH_WARN state is observed, then one should take action to prevent the cluster from halting when it enters the HEALTH_ERROR state.

** Problem 1 **
Ceph status shows an issue with osd, as see in example below

.Example Ceph OSD error
----
cluster:
    id:     263935ae-deb3-47e0-9355-d4a5c935aaf5
    health: HEALTH_ERR
            1 MDSs report slow metadata IOs
            2 osds down
            2 hosts (2 osds) down
            1 nearfull osd(s)
            3 pool(s) nearfull
            11/2142 objects unfound (0.514%)
            Reduced data availability: 237 pgs inactive, 237 pgs down
            Possible data damage: 8 pgs recovery_unfound
            Degraded data redundancy: 833/6426 objects degraded (12.963%), 24 pgs degraded, 63 pgs undersized
 
  services:
    mon: 3 daemons, quorum a,b,c (age 115m)
    mgr: a(active, since 112m)
    mds: myfs:1 {0=myfs-b=up:active} 1 up:standby-replay
    osd: 3 osds: 1 up (since 2m), 3 in (since 113m)
----

.Solving common osd errors:
[source,role="execute"]
----
https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/4/html/troubleshooting_guide/troubleshooting-ceph-osds#most-common-ceph-osd-errors
----
** Problem 2 **
Issues seen with PG, example
.Example Ceph PG error
---
  cluster:
    id:     0a1a6dcb-2146-42f7-9e6f-8b933614c45f
    health: HEALTH_ERR
            Degraded data redundancy: 126/78009 objects degraded (0.162%), 7 pgs degraded
            Degraded data redundancy (low space): 1 pg backfill_toofull

    data:
    pools:   10 pools, 80 pgs
    objects: 26.00k objects, 100 GiB
    usage:   306 GiB used, 5.7 TiB / 6.0 TiB avail
    pgs:     126/78009 objects degraded (0.162%)
             35510/78009 objects misplaced (45.520%)
             55 active+clean
             12 active+remapped+backfill_wait
             4  active+recovery_wait+undersized+degraded+remapped
             3  active+recovery_wait+degraded
             2  active+recovery_wait
             2  active+recovering+undersized+remapped
             1  active+recovering
             1  active+remapped+backfill_toofull
---

.Solving pg error:
[source,role="execute"]
----
https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/4/html/troubleshooting_guide/troubleshooting-ceph-placement-groups#most-common-ceph-placement-group-errors
----



